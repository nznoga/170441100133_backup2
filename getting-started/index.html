



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="A Material Design theme for MkDocs">
      
      
        <link rel="canonical" href="https://nznoga.github.io/170441100133/getting-started/">
      
      
        <meta name="author" content="Nz">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Klasifikasi Menggunakan Decision Tree di R - Noga Gilas Arogan</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#e91e63">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="pink" data-md-color-accent="pink">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#klasifikasi-menggunakan-decision-tree-di-r" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://nznoga.github.io/170441100133/" title="Noga Gilas Arogan" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Noga Gilas Arogan
            </span>
            <span class="md-header-nav__topic">
              Klasifikasi Menggunakan Decision Tree di R
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/nznoga/170441100133/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    nznoga/170441100133
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="KNN (K-Nearest Neighbors)" class="md-tabs__link md-tabs__link--active">
        KNN (K-Nearest Neighbors)
      </a>
    
  </li>

      
        
      
        
      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://nznoga.github.io/170441100133/" title="Noga Gilas Arogan" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Noga Gilas Arogan
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/nznoga/170441100133/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    nznoga/170441100133
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="KNN (K-Nearest Neighbors)" class="md-nav__link">
      KNN (K-Nearest Neighbors)
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Klasifikasi Menggunakan Decision Tree di R
      </label>
    
    <a href="./" title="Klasifikasi Menggunakan Decision Tree di R" class="md-nav__link md-nav__link--active">
      Klasifikasi Menggunakan Decision Tree di R
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#apa-sih-interative-dichotomiser-3" title="Apa sih Interative Dichotomiser 3" class="md-nav__link">
    Apa sih Interative Dichotomiser 3
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reference" title="REFERENCE :" class="md-nav__link">
    REFERENCE :
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../authors-notes/" title="Author's notes" class="md-nav__link">
      Author's notes
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../license/" title="License" class="md-nav__link">
      License
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#apa-sih-interative-dichotomiser-3" title="Apa sih Interative Dichotomiser 3" class="md-nav__link">
    Apa sih Interative Dichotomiser 3
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reference" title="REFERENCE :" class="md-nav__link">
    REFERENCE :
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="klasifikasi-menggunakan-decision-tree-di-r">Klasifikasi Menggunakan Decision Tree di R<a class="headerlink" href="#klasifikasi-menggunakan-decision-tree-di-r" title="Permanent link">&para;</a></h1>
<p><img alt="Material for MkDocs" src="../assets/images/decisionTree.png" /></p>
<p><strong>Classification Tree</strong> sangat populer akhir-akhir ini. Jika Anda tidak pernah mengenalnya, saya yakin kalian pasti tertarik pada Classification Tree. Model ini memungkinkan kalian untuk mengklasifikasikan pengamatan sesuai dengan kualitas pengamatan, yang disebut fitur. Intinya, semua model ini terdiri dari pembuatan pohon, di mana masing-masing node bertindak sebagai router. Contohnya jika kalian memasukkan jamur ke akar pohon, dan kemudian, tergantung pada fitur jamur (ukuran, titik, warna, dll.), kalian akan mengikuti batang sampai ranting yang berbeda-beda untuk sampai ke daun, sehingga baru diketahui kelas jamur kalian, yaitu apakah itu bisa dimakan atau tidak.</p>
<p>Ada dua langkah yang berbeda dalam menggunakan model seperti itu: pelatihan (yaitu membangun pohon), dan memprediksi (yaitu menggunakan pohon untuk memprediksi apakah jamur yang diberikan beracun). Contoh ini memberikan kode untuk melakukan keduanya, dengan menggunakan salah satu algoritma awal untuk mengklasifikasikan data sesuai dengan fitur diskrit: Interative Dichotomiser 3 atau sering disebut ID3. Ini cocok untuk contoh ini, tapi tentu saja saat ini ada algoritma yang lebih rumit dan keren lainnya.</p>
<h4 id="apa-sih-interative-dichotomiser-3">Apa sih Interative Dichotomiser 3<a class="headerlink" href="#apa-sih-interative-dichotomiser-3" title="Permanent link">&para;</a></h4>
<p>Algoritma Decision Tree ID3 menurutku sih, algoritma yang cukup bersemangat dan istiqomah, karena dia meleakukan pencarian secara menyeluruh pada semua kemungkinan pohon keputusan tanpa tertinggal satu pun. Balik ke jamur tadi. Jadi selama tahap prediksi, setiap node mengarahkan jamur kita sesuai dengan fitur. Tapi bagaimana kita memilih fitur itu? Haruskah kita pertama-tama memisahkan himpunan kita menurut warna atau ukuran? Di situlah model klasifikasi berbeda.</p>
<p>Di ID3, kita memilih, di setiap node, fitur dengan Gain Informasi tertinggi. Singkatnya, ini adalah fitur yang membagi sampel di subset yang mungkin paling murni. Misalnya, dalam kasus jamur, titik bisa jadi fitur yang lebih masuk akal daripada organik. Lets Practice !</p>
<p>Pertama kalian harus <strong>install dulu packages "data.tree"</strong> yah, tentunya selanjutnya jalankan. Kita coba menggunakan data yang sudah ada di R yaitu mushroom.</p>
<div class="codehilite"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;data.tree&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">data.tree</span><span class="p">)</span>
</pre></div>

<div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">data.tree</span><span class="p">)</span>
</pre></div>

<p>Nah. sebetulnya untuk kasus ini sudah dibahas di cran.r-project.org. Untuk memudahkan kalian, berikut saya bagikan script yang ada di cran R:</p>
<p>Pertama dibuat dulu nih beberapa fungsi, yang ini untuk mengambil panjang data yang telah unik.</p>
<div class="codehilite"><pre><span></span><span class="n">IsPure</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="p">{</span>
    <span class="nf">length</span><span class="p">(</span><span class="nf">unique</span><span class="p">(</span><span class="n">data[</span><span class="p">,</span><span class="nf">ncol</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="n">]</span><span class="p">))</span> <span class="o">==</span> <span class="m">1</span>
<span class="p">}</span>
</pre></div>

<p><strong>Entropi</strong> adalah ukuran kemurnian dataset. Rumusnya kayak gini (please jangan tanyakan rumusnya dari mana, hehe)</p>
<div class="codehilite"><pre><span></span><span class="n">Entropy</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span> <span class="n">vls</span> <span class="p">)</span> <span class="p">{</span>
  <span class="n">res</span> <span class="o">&lt;-</span> <span class="n">vls</span><span class="o">/</span><span class="nf">sum</span><span class="p">(</span><span class="n">vls</span><span class="p">)</span> <span class="o">*</span> <span class="nf">log2</span><span class="p">(</span><span class="n">vls</span><span class="o">/</span><span class="nf">sum</span><span class="p">(</span><span class="n">vls</span><span class="p">))</span>
  <span class="n">res[vls</span> <span class="o">==</span> <span class="m">0</span><span class="n">]</span> <span class="o">&lt;-</span> <span class="m">0</span>
  <span class="o">-</span><span class="nf">sum</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>

<p>Secara matematis, <strong>Gain Informasi</strong> IG didefinisikan sebagai:
$$
\mathrm{IG}(\mathrm{T}, \mathrm{a})=\mathrm{H}(\mathrm{T})-\sum_{\text { vevals(a)}} \frac{\left|\left{\mathrm{x} \in \mathrm{T} | \mathrm{x}<em>{\mathrm{a}}=\mathrm{v}\right}\right|}{|\mathrm{T}|} \cdot \mathrm{H}\left(\left{\mathrm{x} \in \mathrm{T} | \mathrm{x}</em>{\mathrm{a}}=\mathrm{v}\right}\right)
$$
Dengan kata lain, Gain Informasi mengukur perbedaan antara entropi sebelum perpecahan, dan jumlah bobot entropi setelah perpecahan. Bingung? Sama hehe</p>
<p>So, mari kita tulis langsung dalam bahasa R:</p>
<div class="codehilite"><pre><span></span><span class="n">InformationGain</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span> <span class="n">tble</span> <span class="p">)</span> <span class="p">{</span>
    <span class="n">entropyBefore</span> <span class="o">&lt;-</span> <span class="nf">Entropy</span><span class="p">(</span><span class="nf">colSums</span><span class="p">(</span><span class="n">tble</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">&lt;-</span> <span class="nf">rowSums</span><span class="p">(</span><span class="n">tble</span><span class="p">)</span>
    <span class="n">entropyAfter</span> <span class="o">&lt;-</span> <span class="nf">sum </span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="nf">sum</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="nf">apply</span><span class="p">(</span><span class="n">tble</span><span class="p">,</span> <span class="n">MARGIN</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">FUN</span> <span class="o">=</span> <span class="n">Entropy</span> <span class="p">))</span>
    <span class="n">informationGain</span> <span class="o">&lt;-</span> <span class="n">entropyBefore</span> <span class="o">-</span> <span class="n">entropyAfter</span>
    <span class="nf">return </span><span class="p">(</span><span class="n">informationGain</span><span class="p">)}</span>
</pre></div>

<p>Oke. setelah fungsi-fungsi pendukung siap. selanjutnya kita buat fungsi untuk prediksinya.</p>
<div class="codehilite"><pre><span></span><span class="n">TrainID3</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="p">{</span>

  <span class="n">node</span><span class="o">$</span><span class="n">obsCount</span> <span class="o">&lt;-</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

  <span class="c1">#if the data-set is pure (e.g. all toxic), then</span>
  <span class="nf">if </span><span class="p">(</span><span class="nf">IsPure</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="p">{</span>
    <span class="c1">#construct a leaf having the name of the pure feature (e.g. &#39;toxic&#39;)</span>
    <span class="n">child</span> <span class="o">&lt;-</span> <span class="n">node</span><span class="o">$</span><span class="nf">AddChild</span><span class="p">(</span><span class="nf">unique</span><span class="p">(</span><span class="n">data[</span><span class="p">,</span><span class="nf">ncol</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="n">]</span><span class="p">))</span>
    <span class="n">node</span><span class="o">$</span><span class="n">feature</span> <span class="o">&lt;-</span> <span class="nf">tail</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="m">1</span><span class="p">)</span>
    <span class="n">child</span><span class="o">$</span><span class="n">obsCount</span> <span class="o">&lt;-</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">child</span><span class="o">$</span><span class="n">feature</span> <span class="o">&lt;-</span> <span class="s">&#39;&#39;</span>
  <span class="p">}</span> <span class="n">else</span> <span class="p">{</span>
    <span class="c1">#calculate the information gain</span>
    <span class="n">ig</span> <span class="o">&lt;-</span> <span class="nf">sapply</span><span class="p">(</span><span class="nf">colnames</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="n">[</span><span class="o">-</span><span class="nf">ncol</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="n">]</span><span class="p">,</span> 
            <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="nf">InformationGain</span><span class="p">(</span>
              <span class="nf">table</span><span class="p">(</span><span class="n">data[</span><span class="p">,</span><span class="n">x]</span><span class="p">,</span> <span class="n">data[</span><span class="p">,</span><span class="nf">ncol</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="n">]</span><span class="p">)</span>
              <span class="p">)</span>
            <span class="p">)</span>
    <span class="c1">#chose the feature with the highest information gain (e.g. &#39;color&#39;)</span>
    <span class="c1">#if more than one feature have the same information gain, then take</span>
    <span class="c1">#the first one</span>
    <span class="n">feature</span> <span class="o">&lt;-</span> <span class="nf">names</span><span class="p">(</span><span class="nf">which.max</span><span class="p">(</span><span class="n">ig</span><span class="p">))</span>
    <span class="n">node</span><span class="o">$</span><span class="n">feature</span> <span class="o">&lt;-</span> <span class="n">feature</span>

    <span class="c1">#take the subset of the data-set having that feature value</span>

    <span class="n">childObs</span> <span class="o">&lt;-</span> <span class="nf">split</span><span class="p">(</span><span class="n">data[</span> <span class="p">,</span><span class="nf">names</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">!=</span> <span class="n">feature</span><span class="p">,</span> <span class="n">drop</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="n">]</span><span class="p">,</span> 
                      <span class="n">data[</span> <span class="p">,</span><span class="n">feature]</span><span class="p">,</span> 
                      <span class="n">drop</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

    <span class="nf">for</span><span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="nf">length</span><span class="p">(</span><span class="n">childObs</span><span class="p">))</span> <span class="p">{</span>
      <span class="c1">#construct a child having the name of that feature value (e.g. &#39;red&#39;)</span>
      <span class="n">child</span> <span class="o">&lt;-</span> <span class="n">node</span><span class="o">$</span><span class="nf">AddChild</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">childObs</span><span class="p">)</span><span class="n">[i]</span><span class="p">)</span>

      <span class="c1">#call the algorithm recursively on the child and the subset      </span>
      <span class="nf">TrainID3</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="n">childObs[[i]]</span><span class="p">)</span>
    <span class="p">}</span>

  <span class="p">}</span>

<span class="p">}</span>
</pre></div>

<p>Tahapan yang ditunggu telah tiba. Saatnya kita melakukan training menggunakan data mushroom yang ada di packages data.tree.</p>
<div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">data.tree</span><span class="p">)</span>
<span class="nf">data</span><span class="p">(</span><span class="n">mushroom</span><span class="p">)</span>
<span class="n">mushroom</span>
<span class="c1">##   color  size points edibility</span>
<span class="c1">## 1   red small    yes     toxic</span>
<span class="c1">## 2 brown small     no    edible</span>
<span class="c1">## 3 brown large    yes    edible</span>
<span class="c1">## 4 green small     no    edible</span>
<span class="c1">## 5   red large     no    edible</span>
</pre></div>

<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">&lt;-</span> <span class="n">Node</span><span class="err">$</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;mushroom&quot;</span><span class="p">)</span>
<span class="n">TrainID3</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">mushroom</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="s2">&quot;feature&quot;</span><span class="p">,</span> <span class="s2">&quot;obsCount&quot;</span><span class="p">)</span>
</pre></div>

<p>Nah. hasil tree yang kita dapatkan seperti berikut. Could you understand ? </p>
<div class="codehilite"><pre><span></span><span class="c1">##             levelName   feature obsCount</span>
<span class="c1">## 1  mushroom               color        5</span>
<span class="c1">## 2   ¦--brown          edibility        2</span>
<span class="c1">## 3   ¦   °--edible                      2</span>
<span class="c1">## 4   ¦--green          edibility        1</span>
<span class="c1">## 5   ¦   °--edible                      1</span>
<span class="c1">## 6   °--red                 size        2</span>
<span class="c1">## 7       ¦--large      edibility        1</span>
<span class="c1">## 8       ¦   °--edible                  1</span>
<span class="c1">## 9       °--small      edibility        1</span>
<span class="c1">## 10          °--toxic                   1</span>
</pre></div>

<p>Tentu setelah mendapatkan model, kalian tidak berhenti disitu dong. Kasian modelnya tidak digunakan untuk prediksi. Oke selanjutnya kita akan menggunakan model tersebut untuk melakukan prediksi. Terlebih dahulu kita buat fungsinya.</p>
<div class="codehilite"><pre><span></span><span class="n">Predict</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span> <span class="p">{</span>
  <span class="nf">if </span><span class="p">(</span><span class="n">tree</span><span class="o">$</span><span class="n">children[[1]]</span><span class="o">$</span><span class="n">isLeaf</span><span class="p">)</span> <span class="nf">return </span><span class="p">(</span><span class="n">tree</span><span class="o">$</span><span class="n">children[[1]]</span><span class="o">$</span><span class="n">name</span><span class="p">)</span>
  <span class="n">child</span> <span class="o">&lt;-</span> <span class="n">tree</span><span class="o">$</span><span class="n">children[[features[[tree</span><span class="o">$</span><span class="n">feature]]]]</span>
  <span class="nf">return </span><span class="p">(</span> <span class="nf">Predict</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="n">features</span><span class="p">))</span>
<span class="p">}</span>
</pre></div>

<p>Model sudah tersedia, fungsi untuk melakukan prediksi sudah ada. Selanjutnya kita butuh data apa yang mau diprediksi. nah misalnya kita mau prediksi jika warnanya merah, lalu ukurannya besar, dan memiliki points</p>
<div class="codehilite"><pre><span></span><span class="nf">Predict</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="nf">c</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">&#39;red&#39;</span><span class="p">,</span> 
                <span class="n">size</span> <span class="o">=</span> <span class="s">&#39;large&#39;</span><span class="p">,</span> 
                <span class="n">points</span> <span class="o">=</span> <span class="s">&#39;yes&#39;</span><span class="p">)</span>
        <span class="p">)</span>
</pre></div>

<p>Hasil prediksinya adalah</p>
<div class="codehilite"><pre><span></span><span class="c1">## [1] &quot;edible&quot;</span>
</pre></div>

<p>Bagaimana? Bisa ?</p>
<p>Sebetulnya ada jalan yang lebih pendek, daripada kalian harus membuat fungsi tersebut. Itu hanya buat pembelajaran agar kita bisa lebih memahami flow dari analisis ini yang diberikan oleh Cran R. </p>
<p>Saya akan contohkan cara yang lebih ringkas, cuma 1 baris untuk training model, dan 1 baris untuk testing model. Check it out !</p>
<p>Untuk cara ini, kalian membutuhkan packages "rpart". silahkan di install terlebih dahulu.</p>
<div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">rpart</span><span class="p">)</span>
</pre></div>

<p>Selanjutnya definiskan data yang akan dibuat modelnya</p>
<div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">data.tree</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">yaml</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">mushroom[</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="m">3</span><span class="n">]</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">mushroom[</span><span class="p">,</span><span class="m">4</span><span class="n">]</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

<p>Setelah itu buat modelnya</p>
<div class="codehilite"><pre><span></span><span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">rpart</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&quot;class&quot;</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
</pre></div>

<div class="codehilite"><pre><span></span><span class="c1">## Call:</span>
<span class="c1">## rpart(formula = y_train ~ ., data = x, method = &quot;class&quot;)</span>
<span class="c1">##   n= 5</span>
<span class="c1">## </span>
<span class="c1">##     CP nsplit rel error xerror xstd</span>
<span class="c1">## 1 0.01      0         1      0    0</span>
<span class="c1">## </span>
<span class="c1">## Node number 1: 5 observations</span>
<span class="c1">##   predicted class=edible  expected loss=0.2  P(node) =1</span>
<span class="c1">##     class counts:     4     1</span>
<span class="c1">##    probabilities: 0.800 0.200</span>
</pre></div>

<p>Setelah dapat model, kita lakukan prediksi. Kita coba menggunakan data yang sama dengan script sebelumnya</p>
<div class="codehilite"><pre><span></span><span class="n">color</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="n">size</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;large&quot;</span><span class="p">)</span>
<span class="n">points</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;yes&quot;</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">color</span><span class="p">,</span><span class="n">size</span><span class="p">,</span><span class="n">points</span><span class="p">)</span>
</pre></div>

<p>Lakukan prediksi dengan script berikut</p>
<div class="codehilite"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>

<p>Hasilnya</p>
<div class="codehilite"><pre><span></span><span class="n">predicted</span>
<span class="c1">##       edible  toxic</span>
<span class="c1">## [1,]     0.8    0.2</span>
</pre></div>

<p>Hasil Prediksinya sebesar 0.8 untuk <strong>"edible"</strong>, jadi disimpulkan prediksi jika warnanya merah, ukurannya besar, dan memiliki poin maka edibility terklasifikasi edible. Hasilnya sama dengan menggunakan cara sebelumnya. Tinggal kalian mau memilih pake praktis, atau pake yang agak panjang. <strong>Stay Cool and Keep Improv Your Self Guys.</strong></p>
<h5 id="reference">REFERENCE :<a class="headerlink" href="#reference" title="Permanent link">&para;</a></h5>
<p><a href="http://www.masterstatistik.com/2017/10/klasifikasi-menggunakan-decision-tree.html">Decision Tree di R</a></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href=".." title="KNN (K-Nearest Neighbors)" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                KNN (K-Nearest Neighbors)
              </span>
            </div>
          </a>
        
        
          <a href="../authors-notes/" title="Author's notes" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Author's notes
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016 - 2019 Martin Donath
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="https://www.instagram.com/nznoga_/" class="md-footer-social__link fa fa-instagram"></a>
    
      <a href="https://github.com/nznoga" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/nznoga_" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com/in/" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>